# Pokemon Gemma VLM Training Dependencies
# Production-ready versions for stable training

# Core ML Framework
torch>=2.1.0,<2.3.0
torchvision>=0.16.0,<0.18.0
torchaudio>=2.1.0,<2.3.0

# Transformers and Training
transformers>=4.36.0,<4.42.0
accelerate>=0.25.0,<0.28.0
peft>=0.7.0,<0.9.0
datasets>=2.16.0,<2.20.0
tokenizers>=0.15.0,<0.16.0

# TRL Framework (using local development version)
# trl>=0.7.10,<0.9.0  # Will be installed from repos/trl/

# Computer Vision and Data Processing
pillow>=9.5.0,<11.0.0
opencv-python>=4.8.0,<4.10.0
numpy>=1.24.0,<1.27.0
scipy>=1.10.0,<1.12.0

# Data and IO
pandas>=2.0.0,<2.2.0
pyarrow>=12.0.0,<15.0.0
jsonlines>=3.1.0,<4.0.0

# Monitoring and Logging
wandb>=0.16.0,<0.17.0
tensorboard>=2.14.0,<2.16.0
tqdm>=4.65.0,<4.67.0

# GPU and Performance
nvidia-ml-py3>=7.352.0
psutil>=5.9.0,<6.0.0
gpustat>=1.1.0,<1.2.0

# Development and Debugging
ipython>=8.10.0,<8.20.0
jupyter>=1.0.0,<1.1.0
matplotlib>=3.6.0,<3.9.0
seaborn>=0.12.0,<0.14.0

# Model Optimization and Conversion
optimum>=1.16.0,<1.18.0
bitsandbytes>=0.41.0,<0.44.0

# HuggingFace Integration
huggingface-hub>=0.19.0,<0.21.0
safetensors>=0.4.0,<0.5.0

# System and Environment
python-dotenv>=1.0.0,<1.1.0
packaging>=23.0,<24.0
requests>=2.28.0,<2.32.0
urllib3>=1.26.0,<2.1.0

# Optional: For GGUF conversion
# llama-cpp-python>=0.2.20,<0.3.0

# MLX for Apple Silicon only (not available on Linux servers)
# mlx>=0.26.0,<0.27.0
# mlx-lm>=0.26.0,<0.27.0